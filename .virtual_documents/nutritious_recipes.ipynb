





# Import libraries
import os
import pandas as pd
import requests

# Import API keys
from alyssa_config import spoonacular_key, rapidapi_key
# from lakna_config import spoonacular_key


# Check number of items in the Resources subdirectories, to automate file naming.
def recipe_folder():
    count = len(os.listdir('Resources/01_recipe_IDs'))-1
    return(count)

def raw_folder():
    count = len(os.listdir('Resources/02_raw_data'))-1
    return(count)

def simple_folder():
    count = len(os.listdir('Resources/03_simplified_data'))-1
    return(count)


# Request user input for 'initial_recipes' index of interest.
def check_index():
    try:
        select_folder = input(f"Select file type (recipe, raw, simple): ")
        if (select_folder == "recipe"):
            get_count = recipe_folder()
        elif (select_folder == "raw"):
            get_count = raw_folder()
        elif (select_folder == "simple"):
            get_count = simple_folder()
    except ValueError as e:
        print(f"{e}: Selected file type unknown.")

    try:
        # index = int(input(f"Select file number (0-{recipe_folder()-1}): "))
        index = int(input(f"Select file number (0-{get_count-1}): "))
        return index
    except ValueError as e:
        print(f"{e}: Integer required.")





# Import the FOOD.COM datasets as DataFrames.
food_df = pd.read_csv('Resources/RAW_recipes.csv')
interactions_df = pd.read_csv('Resources/RAW_interactions.csv')


# Get the DataFrame dimensions
interactions_shape = interactions_df.shape
print(f"interactions_df: {interactions_shape}")

# Display the DataFrame
interactions_df.head()


# Get the DataFrame dimensions and columns
food_shape = food_df.shape
print(f"food_df: {food_shape}")
print(food_df.columns)

# Display the DataFrame
food_df.head()





# Check how many recipes have ratings
unique_ratings = len(interactions_df['recipe_id'].unique())
print(f"{unique_ratings} out of {food_shape[0]} have ratings.")

# Check how many recipes have a '0' rating
zero_rating = interactions_df.loc[interactions_df['rating'] == 0]['recipe_id'].unique()
print(f"There are {len(zero_rating)} recipes with a '0' rating.")

# Drop the rows with a '0' rating
nonzero_df = interactions_df.loc[interactions_df['rating'] != 0]
print(f"nonzero_df: {nonzero_df.shape}")


# Create a DataFrame with the average ratings per recipe ID
food_ratings = nonzero_df.groupby('recipe_id')['rating'].mean().reset_index()

# Display the DataFrame
food_ratings.head()


# Rename the recipe ID column for merging with food_df
food_ratings = food_ratings.rename(columns={'recipe_id': 'id'})

# Merge the datasets and display updated DataFrame
merged_food = pd.merge(food_df, food_ratings, on='id')

# Display the DataFrame
merged_shape = merged_food.shape
print(f"merged_food: {merged_shape}")
merged_food.head()





# Identify how to split the nutrition string and convert to float
test_string = merged_food['nutrition']

# Remove the square brackets
test_string = test_string[0].strip("[]")

# Split the string to a list
test_string = test_string.split(", ")

# Cast values to float
test_string = [float(value) for value in test_string]
test_string


# Parse each value in the `nutrition` column
# NOTE: calories (#), total fat (PDV), sugar (PDV), sodium (PDV) , protein (PDV), saturated fat, carbohydrates (PDV)
for df_idx, row in merged_food.iterrows():
    # Strip and split the string to a list
    values_list = row['nutrition'].strip("[]").split(", ")

    # Allocate each nutritional value to the correct column
    for idx, value in enumerate(values_list):
        if (idx == 0):
            merged_food.loc[df_idx, 'Calories'] = float(value)
        elif (idx == 1):
            merged_food.loc[df_idx, 'Total Fat (PDV)'] = float(value)
        elif (idx == 2):
            merged_food.loc[df_idx, 'Sugar (PDV)'] = float(value)
        elif (idx == 3):
            merged_food.loc[df_idx, 'Sodium (PDV)'] = float(value)
        elif (idx == 4):
            merged_food.loc[df_idx, 'Protein (PDV)'] = float(value)
        elif (idx == 5):
            merged_food.loc[df_idx, 'Saturated Fat (PDV)'] = float(value)
        elif (idx == 6):
            merged_food.loc[df_idx, 'Carbohydrates (PDV)'] = float(value)

# Display the DataFrame
merged_food.head()





# Determine whether there are duplicate recipes by ID
dup_id = len(merged_food['id'].unique())
print(f"Unique recipe IDs: {dup_id}, max number of recipes? {merged_shape[0] == dup_id}")

# Determine whether there are duplicate recipes by name
dup_name = len(merged_food['name'].unique())
print(f"Unique recipe names: {dup_name}, max number of recipes? {merged_shape[0] == dup_name}")

# Get the duplicate names - these should be okay
duplicate_names = merged_food.loc[food_df.duplicated(['name'])]
duplicate_names.head()





# Identify how to isolate each tag
tag_string = merged_food['tags'][0].strip("[]")
tag_string = tag_string.split(', ')
tag_string[0].strip("'")

# Get a list of unique tags
unique_tags = []
for string in merged_food['tags']:
    tag_list = string.strip("[]").split(', ')
    for word_idx in range(len(tag_list)):
        tag = tag_list[word_idx].strip("'")
        if tag not in unique_tags:
            unique_tags.append(tag)

# Display the tags alphabetically
sorted(unique_tags)





# Check the tags for meal types
meal_types = ["breakfast", "lunch", "dinner"]
for meal in meal_types:
    if meal in unique_tags:
        print(f"{meal} is a tag.")
    else:
        print(f"{meal} is not a tag.")

# Look for a similar tag to "dinner"
found = False
for tag in unique_tags:
    if (tag[:6] == "dinner"):
        print(f"{tag} is a match.")
        found = True
if (found is False):
    print("No matches found.")


# Count how many rows contain each meal type
updated_meals = ["breakfast", "lunch", "dinner-party"]

break_count = 0
lunch_count = 0
dinner_count = 0
multiple = 0
total = 0

break_list = []
lunch_list = []
dinner_list = []

for idx, string in merged_food.iterrows():
    # Strip and split the string to a list
    tag_list = string['tags'].strip("[]").split(', ')

    # Get each tag from the list and categorise
    for word_idx in range(len(tag_list)):
        # Score tracks mutual exclusivity of the meal types
        score = 0

        # Check the tag
        tag = tag_list[word_idx].strip("'")
        if (tag in updated_meals):
            total += 1
            score = 0
            if (tag == "breakfast"):
                break_list.append(idx)
                break_count += 1
                score += 1
            if (tag == "lunch"):
                lunch_list.append(idx)
                lunch_count += 1
                score += 1
            if (tag == "dinner-party"):
                dinner_list.append(idx)
                dinner_count += 1
                score += 1
        if (score > 1):
            multiple += 1
combined_list = break_count + lunch_count + dinner_count
overlap = not(total == combined_list)
if (overlap is True):
    conclusion = "Recipes exist in more than one meal type."
elif (overlap is False):
    conclusion = "Recipes belong to only one meal type."

# Print findings
print(f"Total recipes with at least one tag: {total}")
print(32*'*')
print(f"Breakfast: {break_count}")
print(f"Lunch: {lunch_count}")
print(f"Dinner: {dinner_count}")
print(32*'*')
print(f"Multiple: {multiple}")
print(f"Checksum: {combined_list}")
print(f"Overlap? {overlap}. {conclusion}")


test_df = merged_food.iloc[break_list]
subset = test_df[['rating', 'n_ingredients']]
subset.plot(kind="scatter", x='rating', y='n_ingredients')


test2_df = merged_food.iloc[combined_list]
print(test2_df.shape)
test2_df.plot(kind="scatter", x="n_steps", y="Calories")


test2_df





input_string = input("List to pass: ")


spoonacular_cuisines = input_string.split(' ')
spoonacular_cuisines = [word.lower() for word in spoonacular_cuisines]
spoonacular_cuisines # DOES NOT ACCOUNT FOR DOUBLE WORD.

# List comprehension to remove double words
double_words = ['eastern', 'european', 'latin', 'american', 'middle']
[spoonacular_cuisines.remove(word) for word in double_words]

# Return the two-word cuisines
spoonacular_cuisines += ['eastern european', 'latin american', 'middle eastern']
spoonacular_cuisines = sorted(spoonacular_cuisines)


# Search for matches with FOOD.COM tags
cuisine_match = []
cuisine_mismatch = []
for cuisine in spoonacular_cuisines:
    if cuisine in unique_tags:
        cuisine_match.append(cuisine)
    else:
        cuisine_mismatch.append(cuisine)
print(f"Cuisine match: ({len(cuisine_match)}), {cuisine_match}")
print(f"Cuisine mismatch: ({len(cuisine_mismatch)}), {cuisine_mismatch}")











# API REQUEST - Complex Search.
recipe_url = "https://api.spoonacular.com/recipes/complexSearch"

# Set request parameters
recipe_params = {
    'apiKey': spoonacular_key,
    'number': 100}

# Request a list of recipes.
recipe_response = requests.get(recipe_url, recipe_params).json()

# Output response to a csv
recipes_df = pd.DataFrame(recipe_response['results'])
recipes_df.to_csv(f'Resources/01_recipe_IDs/initial_recipes_0.csv', index=False)


# Import and display complex search results
recipes_df = pd.read_csv(f'Resources/01_recipe_IDs/initial_recipes_0.csv')
recipes_df.head()


# Check the number of returned recipes
print(f'Number of recipes returned: {len(recipes_df)}')


# API REQUEST - Recipe Information
recipe_info = []
for id in recipes_df['id']:
    info_url = f"https://api.spoonacular.com/recipes/{id}/information?"
    info_params = {
        'apiKey': spoonacular_key,
        'includeNutrition': "true"}

    info_response = requests.get(info_url, info_params).json()
    recipe_info.append(info_response)

info_df = pd.DataFrame(recipe_info)
info_df.to_csv(f'Resources/02_raw_data/info_master_0.csv')


# While the API response is accessible, identify attributes of interest
recipe_info[0].keys()

# Generic metadata
recipe_info[0]['id']
recipe_info[0]['title']
recipe_info[0]['aggregateLikes'] # will need to convert this to a 5-point scale
recipe_info[0]['extendedIngredients'] # can use len() to get the number of ingredients
recipe_info[0]['weightWatcherSmartPoints'] # research the equation for this
recipe_info[0]['cuisines'] # identify recipes with non-empty results
recipe_info[0]['dishTypes'] # will need to select a simpler subset

# Nutritional values - amount, unit, percent of daily needs
recipe_info[0]['nutrition']['nutrients'][0] # Calories
recipe_info[0]['nutrition']['nutrients'][2] # Saturated Fat
recipe_info[0]['nutrition']['nutrients'][5] # Sugar
recipe_info[0]['nutrition']['nutrients'][7] # Sodium
recipe_info[0]['nutrition']['nutrients'][8] # Protein


# Import and display recipe information results
info_df = pd.read_csv(f'Resources/02_raw_data/info_master_0.csv')

# Get the list of column names
info_df.columns

# Display the dataframe
info_df.head()





# API REQUEST - Random Recipe
random_url = "https://api.spoonacular.com/recipes/random?"

# Set request parameters
random_params = {
    'apiKey': spoonacular_key,
    'number': 100}

# Request a list of random recipe IDs.
random_response = requests.get(random_url, random_params).json()

# Output response to a csv
random_df = pd.DataFrame(random_response['recipes'])
random_df.to_csv(f'Resources/01_recipe_IDs/initial_recipes_4.csv', index=False)


# Import and display random recipes results
random_df = pd.read_csv(f'Resources/01_recipe_IDs/initial_recipes_4.csv')
random_df.head()


# Get the list of column name
random_df.columns


# API REQUEST - Recipe Information
recipe_info = []
for id in random_df['id']:
    info_url = f"https://api.spoonacular.com/recipes/{id}/information?"
    info_params = {
        'apiKey': spoonacular_key,
        'includeNutrition': "true"}

    info_response = requests.get(info_url, info_params).json()
    recipe_info.append(info_response)

info_df = pd.DataFrame(recipe_info)
info_df.to_csv(f'Resources/02_raw_data/info_master_4.csv')


# Display the dataframe
info_df.head()





# Metadata
recipe_id = []
recipe_name = []
recipe_likes = []
meal_type = []
cuisines = []
num_ingredients = []
ww_points = []

# Calories
calories_amt = []
calories_unit = []
calories_pct = []

# Saturated Fat
satfat_amt = []
satfat_unit = []
satfat_pct = []

# Sugar
sugar_amt = []
sugar_unit = []
sugar_pct = []

# Sodium
sodium_amt = []
sodium_unit = []
sodium_pct = []

# Protein
protein_amt = []
protein_unit = []
protein_pct = []

for idx, row in enumerate(recipe_info):
    try:
        recipe_id.append(recipe_info[idx]['id'])
        recipe_name.append(recipe_info[idx]['title'])
        recipe_likes.append(recipe_info[idx]['aggregateLikes'])
        meal_type.append(recipe_info[idx]['dishTypes'])
        cuisines.append(recipe_info[idx]['cuisines'])
        num_ingredients.append(len(recipe_info[idx]['extendedIngredients']))
        ww_points.append(recipe_info[idx]['weightWatcherSmartPoints'])
        
        calories_amt.append(recipe_info[idx]['nutrition']['nutrients'][0]['amount'])
        calories_unit.append(recipe_info[idx]['nutrition']['nutrients'][0]['unit'])
        calories_pct.append(recipe_info[idx]['nutrition']['nutrients'][0]['percentOfDailyNeeds'])
        
        satfat_amt.append(recipe_info[idx]['nutrition']['nutrients'][2]['amount'])
        satfat_unit.append(recipe_info[idx]['nutrition']['nutrients'][2]['unit'])
        satfat_pct.append(recipe_info[idx]['nutrition']['nutrients'][2]['percentOfDailyNeeds'])
        
        sugar_amt.append(recipe_info[idx]['nutrition']['nutrients'][5]['amount'])
        sugar_unit.append(recipe_info[idx]['nutrition']['nutrients'][5]['unit'])
        sugar_pct.append(recipe_info[idx]['nutrition']['nutrients'][5]['percentOfDailyNeeds'])
        
        sodium_amt.append(recipe_info[idx]['nutrition']['nutrients'][7]['amount'])
        sodium_unit.append(recipe_info[idx]['nutrition']['nutrients'][7]['unit'])
        sodium_pct.append(recipe_info[idx]['nutrition']['nutrients'][7]['percentOfDailyNeeds'])
        
        protein_amt.append(recipe_info[idx]['nutrition']['nutrients'][8]['amount'])
        protein_unit.append(recipe_info[idx]['nutrition']['nutrients'][8]['unit'])
        protein_pct.append(recipe_info[idx]['nutrition']['nutrients'][8]['percentOfDailyNeeds'])
    
    except:
        print(idx)

spoonacular_df = pd.DataFrame({
    'ID': recipe_id,
    'Name': recipe_name,
    'Likes': recipe_likes,
    'Meal Type': meal_type,
    'Cuisines': cuisines,
    'N_ingredients': num_ingredients,
    'WW Smart Points': ww_points,
    'Calories (Amount)': calories_amt,
    'Calories (Unit)': calories_unit,
    'Calories (% of Daily Needs)': calories_pct,
    'Saturated Fat (Amount)': satfat_amt,
    'Saturated Fat (Unit)': satfat_unit,
    'Saturated Fat (% of Daily Needs)': satfat_pct,
    'Sugar (Amount)': sugar_amt,
    'Sugar (Unit)': sugar_unit,
    'Sugar (% of Daily Needs)': sugar_pct,
    'Sodium (Amount)': sodium_amt,
    'Sodium (Unit)': sodium_unit,
    'Sodium (% of Daily Needs)': sodium_pct,
    'Protein (Amount)': protein_amt,
    'Protein (Unit)': protein_unit,
    'Protein (% of Daily Needs)': protein_pct})

spoonacular_df.to_csv(f"Resources/03_simplified_data/initial_nutrition_4.csv", index=False)


# Check the units columns
units_columns = ['Calories (Unit)', 'Saturated Fat (Unit)', 'Sugar (Unit)', 'Sodium (Unit)', 'Protein (Unit)']
for col in units_columns:
    check = spoonacular_df['Protein (Unit)'].unique()
    print(f"Unit check: {col} {check}")





# API REQUEST - Random Recipe
random_url = "https://api.spoonacular.com/recipes/random?"

# Set request parameters
random_params = {
    'apiKey': spoonacular_key,
    'number': 100}

# Request a list of random recipe IDs.
random_response = requests.get(random_url, random_params).json()

# Output response to a csv
random_df = pd.DataFrame(random_response['recipes'])
random_df.to_csv('Resources/01_recipe_IDs/initial_recipes_5.csv', index=False)


# API REQUEST - Nutrition by ID
nutrition_info = []
for id in random_df['id']:
    nutrition_url = f"https://api.spoonacular.com/recipes/{id}/nutritionWidget.json"
    nutrition_params = {'apiKey': spoonacular_key}

    nutrition_response = requests.get(nutrition_url, nutrition_params).json()
    nutrition_info.append(nutrition_response)

nutrition_df = pd.DataFrame(nutrition_info)
nutrition_df.to_csv('Resources/02_raw_data/info_master_5.csv')


metadata.columns


nutrition_info[0]['carbs']


# Parse results
metadata = pd.read_csv('Resources/01_recipe_IDs/initial_recipes_5.csv')
metadata

# Metadata
num_ingredients = []
carbs = []
# for row in metadata['extendedIngredients']:
#     print(row)

# Calories
calories_amt = []
calories_unit = []
calories_pct = []

# Saturated Fat
satfat_amt = []
satfat_unit = []
satfat_pct = []

# Sugar
sugar_amt = []
sugar_unit = []
sugar_pct = []

# Sodium
sodium_amt = []
sodium_unit = []
sodium_pct = []

# Protein
protein_amt = []
protein_unit = []
protein_pct = []

for idx, row in enumerate(nutrition_info):
    try:
        # recipe_id.append(nutrition_info[idx]['id'])
        # recipe_name.append(nutrition_info[idx]['title'])
        # recipe_likes.append(nutrition_info[idx]['aggregateLikes'])
        # meal_type.append(nutrition_info[idx]['dishTypes'])
        # cuisines.append(nutrition_info[idx]['cuisines'])
        # num_ingredients.append(len(recipe_info[idx]['extendedIngredients']))
        # ww_points.append(recipe_info[idx]['weightWatcherSmartPoints'])

        num_ingredients.append(len(nutrition_info[idx]['ingredients']))
        carbs.append(nutrition_info[idx]['carbs'])
        calories_amt.append(nutrition_info[idx]['nutrients'][0]['amount'])
        calories_unit.append(nutrition_info[idx]['nutrients'][0]['unit'])
        calories_pct.append(nutrition_info[idx]['nutrients'][0]['percentOfDailyNeeds'])
        
        satfat_amt.append(nutrition_info[idx]['nutrients'][2]['amount'])
        satfat_unit.append(nutrition_info[idx]['nutrients'][2]['unit'])
        satfat_pct.append(nutrition_info[idx]['nutrients'][2]['percentOfDailyNeeds'])
        
        sugar_amt.append(nutrition_info[idx]['nutrients'][5]['amount'])
        sugar_unit.append(nutrition_info[idx]['nutrients'][5]['unit'])
        sugar_pct.append(nutrition_info[idx]['nutrients'][5]['percentOfDailyNeeds'])
        
        sodium_amt.append(nutrition_info[idx]['nutrients'][7]['amount'])
        sodium_unit.append(nutrition_info[idx]['nutrients'][7]['unit'])
        sodium_pct.append(nutrition_info[idx]['nutrients'][7]['percentOfDailyNeeds'])
        
        protein_amt.append(nutrition_info[idx]['nutrients'][8]['amount'])
        protein_unit.append(nutrition_info[idx]['nutrients'][8]['unit'])
        protein_pct.append(nutrition_info[idx]['nutrients'][8]['percentOfDailyNeeds'])
    
    except:
        print(idx)

spoonacular_df = pd.DataFrame({
    'ID': metadata['id'],
    'Name': metadata['title'],
    'Likes': metadata['aggregateLikes'],
    'Meal Type': metadata['dishTypes'],
    'Cuisines': metadata['cuisines'],
    'N_ingredients': num_ingredients,
    'WW Smart Points': metadata['weightWatcherSmartPoints'],
    'Calories (Amount)': calories_amt,
    'Calories (Unit)': calories_unit,
    'Calories (% of Daily Needs)': calories_pct,
    'Saturated Fat (Amount)': satfat_amt,
    'Saturated Fat (Unit)': satfat_unit,
    'Saturated Fat (% of Daily Needs)': satfat_pct,
    'Sugar (Amount)': sugar_amt,
    'Sugar (Unit)': sugar_unit,
    'Sugar (% of Daily Needs)': sugar_pct,
    'Sodium (Amount)': sodium_amt,
    'Sodium (Unit)': sodium_unit,
    'Sodium (% of Daily Needs)': sodium_pct,
    'Protein (Amount)': protein_amt,
    'Protein (Unit)': protein_unit,
    'Protein (% of Daily Needs)': protein_pct,
    'Carbohydrates': carbs})

spoonacular_df.to_csv(f"Resources/03_simplified_data/initial_nutrition_5.csv", index=False)





# API REQUEST - Random Recipe
random_url = "https://api.spoonacular.com/recipes/random?"

# Set request parameters
random_params = {
    'apiKey': spoonacular_key,
    'number': 100}

# Request a list of random recipe IDs.
random_response = requests.get(random_url, random_params).json()

# Output response to a csv
random_df = pd.DataFrame(random_response['recipes'])
random_df.to_csv(f'Resources/01_recipe_IDs/initial_recipes_{recipe_folder()}.csv', index=False)


# API REQUEST - Nutrition by ID
nutrition_info = []
for id in random_df['id']:
    nutrition_url = f"https://api.spoonacular.com/recipes/{id}/nutritionWidget.json"
    nutrition_params = {'apiKey': spoonacular_key}

    nutrition_response = requests.get(nutrition_url, nutrition_params).json()
    nutrition_info.append(nutrition_response)

nutrition_df = pd.DataFrame(nutrition_info)
nutrition_df.to_csv(f'Resources/02_raw_data/info_master_{raw_folder()}.csv')


# Parse results
metadata = pd.read_csv(f'Resources/01_recipe_IDs/initial_recipes_{recipe_folder()-1}.csv')
metadata

# Metadata
num_ingredients = []
carbs = []
# for row in metadata['extendedIngredients']:
#     print(row)

# Calories
calories_amt = []
calories_unit = []
calories_pct = []

# Saturated Fat
satfat_amt = []
satfat_unit = []
satfat_pct = []

# Sugar
sugar_amt = []
sugar_unit = []
sugar_pct = []

# Sodium
sodium_amt = []
sodium_unit = []
sodium_pct = []

# Protein
protein_amt = []
protein_unit = []
protein_pct = []

for idx, row in enumerate(nutrition_info):
    try:
        # recipe_id.append(nutrition_info[idx]['id'])
        # recipe_name.append(nutrition_info[idx]['title'])
        # recipe_likes.append(nutrition_info[idx]['aggregateLikes'])
        # meal_type.append(nutrition_info[idx]['dishTypes'])
        # cuisines.append(nutrition_info[idx]['cuisines'])
        # num_ingredients.append(len(recipe_info[idx]['extendedIngredients']))
        # ww_points.append(recipe_info[idx]['weightWatcherSmartPoints'])

        num_ingredients.append(len(nutrition_info[idx]['ingredients']))
        carbs.append(nutrition_info[idx]['carbs'])
        calories_amt.append(nutrition_info[idx]['nutrients'][0]['amount'])
        calories_unit.append(nutrition_info[idx]['nutrients'][0]['unit'])
        calories_pct.append(nutrition_info[idx]['nutrients'][0]['percentOfDailyNeeds'])
        
        satfat_amt.append(nutrition_info[idx]['nutrients'][2]['amount'])
        satfat_unit.append(nutrition_info[idx]['nutrients'][2]['unit'])
        satfat_pct.append(nutrition_info[idx]['nutrients'][2]['percentOfDailyNeeds'])
        
        sugar_amt.append(nutrition_info[idx]['nutrients'][5]['amount'])
        sugar_unit.append(nutrition_info[idx]['nutrients'][5]['unit'])
        sugar_pct.append(nutrition_info[idx]['nutrients'][5]['percentOfDailyNeeds'])
        
        sodium_amt.append(nutrition_info[idx]['nutrients'][7]['amount'])
        sodium_unit.append(nutrition_info[idx]['nutrients'][7]['unit'])
        sodium_pct.append(nutrition_info[idx]['nutrients'][7]['percentOfDailyNeeds'])
        
        protein_amt.append(nutrition_info[idx]['nutrients'][8]['amount'])
        protein_unit.append(nutrition_info[idx]['nutrients'][8]['unit'])
        protein_pct.append(nutrition_info[idx]['nutrients'][8]['percentOfDailyNeeds'])
    
    except:
        print(idx)
        pass

spoonacular_df = pd.DataFrame({
    'ID': metadata['id'],
    'Name': metadata['title'],
    'Likes': metadata['aggregateLikes'],
    'Meal Type': metadata['dishTypes'],
    'Cuisines': metadata['cuisines'],
    'N_ingredients': num_ingredients,
    'WW Smart Points': metadata['weightWatcherSmartPoints'],
    'Calories (Amount)': calories_amt,
    'Calories (Unit)': calories_unit,
    'Calories (% of Daily Needs)': calories_pct,
    'Saturated Fat (Amount)': satfat_amt,
    'Saturated Fat (Unit)': satfat_unit,
    'Saturated Fat (% of Daily Needs)': satfat_pct,
    'Sugar (Amount)': sugar_amt,
    'Sugar (Unit)': sugar_unit,
    'Sugar (% of Daily Needs)': sugar_pct,
    'Sodium (Amount)': sodium_amt,
    'Sodium (Unit)': sodium_unit,
    'Sodium (% of Daily Needs)': sodium_pct,
    'Protein (Amount)': protein_amt,
    'Protein (Unit)': protein_unit,
    'Protein (% of Daily Needs)': protein_pct,
    'Carbohydrates': carbs})

spoonacular_df.to_csv(f"Resources/03_simplified_data/initial_nutrition_{simple_folder()}.csv", index=False)





simplified_data = pd.read_csv('Resources/03_simplified_data/initial_nutrition_0.csv')
simplified_data.columns
simplified_data.shape


raw_data = pd.read_csv('Resources/02_raw_data/info_master_0.csv')
raw_data['weightWatcherSmartPoints']


simplified_data.insert(6, column='WW Smart Points', value=raw_data['weightWatcherSmartPoints'])


simplified_data.head()


simplified_data.to_csv('Resources/03_simplified_data/initial_nutrition_0.csv', index=False)



